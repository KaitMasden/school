{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data \n",
    "The data we used was a collection of tweets from NBC Health."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the required packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import csv\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics, svm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, learning_curve, StratifiedShuffleSplit, GridSearchCV,\n",
    "    cross_val_score)\n",
    "\n",
    "# Improve the readability of figures\n",
    "sns.set_context('notebook', font_scale=1.4)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>585978391360221184|Thu Apr 09 01:31:50 +0000 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>585947808772960257|Wed Apr 08 23:30:18 +0000 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>585947807816650752|Wed Apr 08 23:30:18 +0000 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>585866060991078401|Wed Apr 08 18:05:28 +0000 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>585794106170839041|Wed Apr 08 13:19:33 +0000 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  585978391360221184|Thu Apr 09 01:31:50 +0000 2...\n",
       "1  585947808772960257|Wed Apr 08 23:30:18 +0000 2...\n",
       "2  585947807816650752|Wed Apr 08 23:30:18 +0000 2...\n",
       "3  585866060991078401|Wed Apr 08 18:05:28 +0000 2...\n",
       "4  585794106170839041|Wed Apr 08 13:19:33 +0000 2..."
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_table('bbchealth.txt', header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3929 entries, 0 to 3928\n",
      "Data columns (total 1 columns):\n",
      "0    3929 non-null object\n",
      "dtypes: object(1)\n",
      "memory usage: 30.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we have 3929 tweets in the collection. \n",
    "\n",
    "However, there's metadata before each of the tweet messages and a link to a bbchealth article at the end. So we will have to preprocess the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = \"583659491310219264|Thu Apr 02 15:57:21 +0000 2015|Unsafe food 'growing global threat' http://bbc.in/1BREQDJ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing stopwords\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove word stems using a Porter stemmer\n",
    "porter = nltk.PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(messy_string):\n",
    "    assert(type(messy_string) == str)\n",
    "    cleaned = messy_string\n",
    "    cleaned = re.sub(r'\\d+\\|.+\\|', '', messy_string)\n",
    "    cleaned = re.sub(r'(http[s]?\\S+)|(\\w+\\.[A-Za-z]{2,4}\\S*)', '',\n",
    "                     cleaned)\n",
    "    cleaned = re.sub(r'[^\\w\\d\\s]', ' ', cleaned)\n",
    "    cleaned = re.sub(r'\\s+', ' ', cleaned)\n",
    "    cleaned = re.sub(r'^\\s+|\\s+?$', '', cleaned.lower())\n",
    "    return ' '.join(\n",
    "        porter.stem(term) \n",
    "        for term in cleaned.split()\n",
    "        if term not in set(stop_words)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unsaf food grow global threat'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_text(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = df[0]\n",
    "processed = raw_text.apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction and Vectorizing\n",
    "\n",
    "## TfidVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 62 ms\n",
      "(3929, 1)\n"
     ]
    }
   ],
   "source": [
    "#define vectorizer parameters\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=200000,\n",
    "                                 min_df=0.2, stop_words='english',\n",
    "                                 use_idf=True, ngram_range=(1,3))\n",
    "\n",
    "%time tfidf_matrix = tfidf_vectorizer.fit_transform(processed) #fit the vectorizer to synopses\n",
    "\n",
    "print(tfidf_matrix.shape)\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "dist = 1 - cosine_similarity(tfidf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_k = 5\n",
    "kmeans = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0:\n",
      " audio\n",
      " cancer\n",
      " nh\n",
      " warn\n",
      " care\n",
      " amp\n",
      " need\n",
      " health\n",
      " drug\n",
      " drink\n",
      "Cluster 1:\n",
      " nh\n",
      " cancer\n",
      " hospit\n",
      " care\n",
      " health\n",
      " patient\n",
      " death\n",
      " drug\n",
      " new\n",
      " call\n",
      "Cluster 2:\n",
      " test\n",
      " diseas\n",
      " cancer\n",
      " blood\n",
      " heart\n",
      " risk\n",
      " could\n",
      " liver\n",
      " save\n",
      " find\n",
      "Cluster 3:\n",
      " ebola\n",
      " video\n",
      " uk\n",
      " vaccin\n",
      " case\n",
      " leon\n",
      " nurs\n",
      " liberia\n",
      " sierra\n",
      " trial\n",
      "Cluster 4:\n",
      " video\n",
      " nh\n",
      " health\n",
      " cancer\n",
      " help\n",
      " care\n",
      " mental\n",
      " new\n",
      " patient\n",
      " gp\n"
     ]
    }
   ],
   "source": [
    "kmeans.fit(cX)\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = cvectorizer.get_feature_names()\n",
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind]),\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.cluster.k_means_.KMeans"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the size of the plot\n",
    "plt.figure(figsize=(3929, 3233))\n",
    "\n",
    "# Create a colormap\n",
    "colormap = np.array(['red', 'lime', 'black'])\n",
    "\n",
    "# Plot Sepal\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(x.Sepal_Length, x.Sepal_Width, c=colormap[y.Targets], s=40)\n",
    "plt.title('Sepal')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(x.Petal_Length, x.Petal_Width, c=colormap[y.Targets], s=40)\n",
    "plt.title('Petal')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
